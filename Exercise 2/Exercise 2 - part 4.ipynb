{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/qkg2E2D.png)\n",
    "\n",
    "# UnSupervised Learning Methods\n",
    "\n",
    "## Exercise 002 - Part IV\n",
    "\n",
    "> Notebook by:\n",
    "> - Royi Avital RoyiAvital@fixelalgorithms.com\n",
    "\n",
    "## Revision History\n",
    "\n",
    "| Version | Date       | User        |Content / Changes                                                   |\n",
    "|---------|------------|-------------|--------------------------------------------------------------------|\n",
    "| 0.1.000 | 03/04/2023 | Royi Avital | First version                                                      |\n",
    "|         |            |             |                                                                    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FixelAlgorithmsTeam/FixelCourses/blob/master/UnSupervisedLearningMethods/2023_03/Exercise0002Part004.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:25.653418Z",
     "start_time": "2023-05-17T15:55:24.652154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "# General Tools\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Computer Vision\n",
    "\n",
    "# Statistics\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "import math\n",
    "from platform import python_version\n",
    "import random\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "# Typing\n",
    "from typing import Callable, List, Tuple, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter\n",
    "from IPython import get_ipython\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import Dropdown, FloatSlider, interact, IntSlider, Layout\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "* <font color='red'>(**?**)</font> Question to answer interactively.\n",
    "* <font color='blue'>(**!**)</font> Simple task to add code for the notebook.\n",
    "* <font color='green'>(**@**)</font> Optional / Extra self practice.\n",
    "* <font color='brown'>(**#**)</font> Note / Useful resource / Food for thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:25.707499Z",
     "start_time": "2023-05-17T15:55:25.656521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "%matplotlib inline\n",
    "\n",
    "seedNum = 512\n",
    "np.random.seed(seedNum)\n",
    "random.seed(seedNum)\n",
    "\n",
    "# sns.set_theme() #>! Apply SeaBorn theme\n",
    "\n",
    "runInGoogleColab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:25.707958Z",
     "start_time": "2023-05-17T15:55:25.686880Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "DATA_FILE_URL   = r'https://drive.google.com/uc?export=download&confirm=9iBg&id=11YqtdWwZSNE-0KxWAf1ZPINi9-ar56Na'\n",
    "DATA_FILE_NAME  = r'ClusteringData.npy'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines\n",
    "\n",
    " - Fill the full names and ID's of the team members in the `Team Members` section.\n",
    " - Answer all questions / tasks within the Jupyter Notebook.\n",
    " - Use MarkDown + MathJaX + Code to answer.\n",
    " - Verify the rendering on VS Code.\n",
    " - Submission in groups (Single submission per group).\n",
    " - You may and _should_ use the forums for questions.\n",
    " - Good Luck!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='brown'>(**#**)</font> The `Import Packages` section above imports most needed tools to apply the work. Please use it.\n",
    "* <font color='brown'>(**#**)</font> You may replace the suggested functions to use with functions from other packages.\n",
    "* <font color='brown'>(**#**)</font> Whatever not said explicitly to implement maybe used by a 3rd party packages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "\n",
    "- `Nadav_Talmon_203663950`.\n",
    "- `Nadav_Shaked_312494925`.\n",
    "- `Adi_Rosenthal_316550797`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate / Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:25.708236Z",
     "start_time": "2023-05-17T15:55:25.694925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download Data\n",
    "# This section downloads data from the given URL if needed.\n",
    "\n",
    "if not os.path.exists(DATA_FILE_NAME):\n",
    "    urllib.request.urlretrieve(DATA_FILE_URL, DATA_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:25.726923Z",
     "start_time": "2023-05-17T15:55:25.711896Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate / Load Data\n",
    "\n",
    "numSamples  = 1000\n",
    "mA          =  np.array([[0.6, -0.6], [-0.4, 0.8]])\n",
    "\n",
    "mX1 = datasets.make_circles(n_samples = numSamples, noise = 0.02)[0]\n",
    "mX2 = datasets.make_moons(n_samples = numSamples, noise = 0.05)[0]\n",
    "mX3 = datasets.make_blobs(n_samples = numSamples, random_state = 170)[0] @ mA\n",
    "mX4 = datasets.make_blobs(n_samples = numSamples, random_state = 170, cluster_std = [0.8, 2, 0.4])[0] \n",
    "mX5 = np.load(DATA_FILE_NAME)\n",
    "\n",
    "lDataSet = [mX1, mX2, mX3, mX4, mX5]\n",
    "numDataSets = len(lDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:27.876927Z",
     "start_time": "2023-05-17T15:55:25.747745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot Data\n",
    "hF, hAs = plt.subplots(nrows = 1, ncols = numDataSets, figsize = (18, 5))\n",
    "hAs = hAs.flat\n",
    "\n",
    "for ii, hA in enumerate(hAs):\n",
    "    mX = lDataSet[ii]\n",
    "    hA.scatter(mX[:, 0], mX[:, 1], c = 'lime', s = 15, edgecolor = 'k')\n",
    "    hA.axis('equal')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Clustering by Density based Spatial Clustering of Applications with Noise (DBSCAN)\n",
    "\n",
    "### 8.1. DBSCAN Algorithm\n",
    "\n",
    "In this section we'll implement the DBSCAN algorithm:\n",
    "\n",
    "1. Implement an auxiliary function to compute the connected components (`GetConnectedComponents()`).  \n",
    "   You may choose any implementation strategy (`DFS` / `BFS`, ect...).\n",
    "2. Implement the function `DBSCAN()`.  \n",
    "   The function should label noise points as `-1`.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Implementation should be efficient (Memory and operations). Total run time expected to be **less than 20 seconds**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:27.890544Z",
     "start_time": "2023-05-17T15:55:27.876460Z"
    }
   },
   "outputs": [],
   "source": [
    "def GetConnectedComponents(mG: np.ndarray, core_points: np.ndarray) -> np.ndarray:\n",
    "    '''\n",
    "    Extract the connected components of a graph.\n",
    "    Args:\n",
    "        mG          - Graph matrix.\n",
    "    Output:\n",
    "        vL          - Label per component.\n",
    "    Remarks:\n",
    "        - This is a !!BFS / DFS!! implementation.\n",
    "    '''\n",
    "\n",
    "    def dfs(node, component):\n",
    "        stack = [node]\n",
    "        while stack:\n",
    "            n = stack.pop()\n",
    "            if vL[n] == 0:\n",
    "                vL[n] = component\n",
    "                if core_points[n]:\n",
    "                    neighbors = np.where(mG[n] != 0)[0]\n",
    "                    stack.extend(neighbors)\n",
    "\n",
    "    N = mG.shape[0]\n",
    "    vL = np.zeros(N)  # Component labels\n",
    "    component = 1  # Current component label\n",
    "\n",
    "    for i in range(N):\n",
    "        if core_points[i] and vL[i] == 0:\n",
    "            dfs(i, component)\n",
    "            component += 1\n",
    "\n",
    "    return vL.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:27.952251Z",
     "start_time": "2023-05-17T15:55:27.902237Z"
    }
   },
   "outputs": [],
   "source": [
    "def DBSCAN(mX: np.ndarray, Z: int, r: float) -> np.ndarray:\n",
    "    '''\n",
    "    DBSCAN Algorithm.\n",
    "    Args:\n",
    "        mX  - Input data with shape N x d.\n",
    "        Z   - Number of points required to be a core point.\n",
    "        r   - Neighborhood radius.\n",
    "    Output:\n",
    "        vL  - The labels (-1, 0, 1, .., K - 1) per sample with shape (N, ).\n",
    "    Remarks:\n",
    "        - Clusters will have the labels {0, 1, ..., K - 1}.\n",
    "        - Noise samples will have the label `-1`.\n",
    "    '''\n",
    "\n",
    "    # Step 1: Find core points\n",
    "    mD = euclidean_distances(mX)  # Pairwise distance matrix\n",
    "    core_points = np.sum(mD <= r, axis=1) >= Z\n",
    "\n",
    "    # Step 2: Build the graph\n",
    "    mG = np.where(mD <= r, 1, 0)  # Adjacency matrix\n",
    "\n",
    "    # Step 3: Find connected components\n",
    "    labels = GetConnectedComponents(mG, core_points)  # Connected components\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Clustering the Data Set\n",
    "\n",
    "In this section we'll use the implementation of the DSCAN algorithm.\n",
    "The tasks are:\n",
    "\n",
    "1. Use the data set `mX4`.\n",
    "2. Tweak the parameters until you have 3 clusters.\n",
    "3. Display results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:28.048145Z",
     "start_time": "2023-05-17T15:55:27.914861Z"
    }
   },
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Set parameters.\n",
    "# 2. Apply the algorithm.\n",
    "\n",
    "Z = 5\n",
    "r = 0.688\n",
    "labels = DBSCAN(mX4, Z, r)\n",
    "label_unique = np.sort(np.unique(labels))\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:28.647664Z",
     "start_time": "2023-05-17T15:55:28.012877Z"
    }
   },
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# 1. Plot the clustered data.\n",
    "# !! The noise samples should also be labeled.\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "unique_labels = set(labels) - {-1}\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "noise_samples = mX4[labels == 0]\n",
    "\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    if label == 0:\n",
    "        continue  # Skip noise samples for now\n",
    "    cluster_samples = mX4[labels == label]\n",
    "    ax.scatter(cluster_samples[:, 0], cluster_samples[:, 1], color=color, label=f'Cluster {label}')\n",
    "\n",
    "ax.scatter(noise_samples[:, 0], noise_samples[:, 1], color='black', label='Noise', marker='x')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('DBSCAN Clustering')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.show()\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. An Algorithm to Set the Parameters Automatically Given a Data Set\n",
    "\n",
    "Can you think about an algorithm to automatically infer optimal parameters of the DBSCAN algorithm given a data set?   \n",
    "\n",
    "1. Sketch the algorithm (Words / Diagram).\n",
    "2. Implement and test on `mX4`.\n",
    "3. Plot the results.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> Run time should be reasonable (Single number of seconds).\n",
    "* <font color='brown'>(**#**)</font> Good answers might be given a bonus points of up to 4 points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3. Solution\n",
    "\n",
    "The algorithm uses a systematic approach to find the best r value for each num_points by idea that the k-nearest neighbor (KNN) distance can represent the density of the data.\n",
    "\n",
    "The algorithm evaluates different combinations of r and num_points by utilizing the Silhouette Coefficient. This coefficient measures the fit of each sample within its assigned cluster by comparing the average distance to other samples in the same cluster with the average distance to samples in the nearest neighboring cluster.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:28.659069Z",
     "start_time": "2023-05-17T15:55:28.652712Z"
    }
   },
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# Implement a function which gets a data set and output the `Z` and `r` parameters of `DBSCAN()`.\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def get_dbscan_parameters(data):\n",
    "    best_score = 0\n",
    "    best_params = {}\n",
    "    labels_max = None\n",
    "    for num_points in np.arange(2, 20):\n",
    "        nbrs = NearestNeighbors(n_neighbors=num_points).fit(data)\n",
    "\n",
    "        distances, indices = nbrs.kneighbors(data)\n",
    "\n",
    "        distances = np.sort(distances, axis=0)\n",
    "        distances = distances[:, num_points - 1]\n",
    "        for ratio in np.arange(0.75, 1.0, 0.05):\n",
    "            r = distances[int(len(distances) * ratio)]\n",
    "            labels = DBSCAN(data, num_points, r)\n",
    "            # The Silhouette Coefficient - calc mean intra-cluster distance (`a`) and the mean nearest-cluster distance (``b``) for each\n",
    "            # sample.  The Silhouette Coefficient for a sample is ``(b - a) / max(a,b)``.\n",
    "            if len(np.unique(labels)) > 1:\n",
    "                score = silhouette_score(data, labels)\n",
    "            else:\n",
    "                score = 0\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                labels_max = labels\n",
    "                best_params = {'r': r, 'num_points': num_points}\n",
    "    return best_params[\"r\"], best_params[\"num_points\"]\n",
    "    \n",
    "#===============================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T15:55:37.728374Z",
     "start_time": "2023-05-17T15:55:28.667330Z"
    }
   },
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# Test your algorithm on `mX4` data set. Show results.\n",
    "\n",
    "data = mX4\n",
    "r, Z = get_dbscan_parameters(data)\n",
    "print(f\"r: {r}\")\n",
    "print(f\"Z: {Z}\")\n",
    "\n",
    "labels = DBSCAN(data, Z, r)\n",
    "label_unique = np.sort(np.unique(labels))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "unique_labels = set(labels) - {-1}\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "noise_samples = data[labels == 0]\n",
    "\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    if label == 0:\n",
    "        continue  # Skip noise samples for now\n",
    "    cluster_samples = data[labels == label]\n",
    "    ax.scatter(cluster_samples[:, 0], cluster_samples[:, 1], color=color, label=f'Cluster {label}')\n",
    "\n",
    "ax.scatter(noise_samples[:, 0], noise_samples[:, 1], color='black', label='Noise', marker='x')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('DBSCAN Clustering')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.show()\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Royi: <font color='green'>✓ +2 Points (Bonus)</font>. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4. Test Methods on the Data Set\n",
    "\n",
    "In this section we'll compare 4 methods on each data set.  \n",
    "The 4th methods is `AgglomerativeClustering` which is imported from `SciKit Learn`.\n",
    "\n",
    "1. Run each method on each data set.\n",
    "2. Plot a grid of results (Using `plt.subplots()`): Each row is a different method, each column is a different data set.\n",
    "3. Optimize the parameters per data set per method.\n",
    "\n",
    "The final result is a grid of `4 x 5` scatter plots.\n",
    "\n",
    "* <font color='brown'>(**#**)</font> You should use `CourseAuxFun.py` and import your self implemented functions from the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T16:08:00.252156Z",
     "start_time": "2023-05-17T16:00:39.318941Z"
    }
   },
   "outputs": [],
   "source": [
    "#===========================Fill This===========================#\n",
    "# Display the results of each method\n",
    "\n",
    "from CourseAuxFun_GRP_F import *\n",
    "\n",
    "def KMeans_lambda(data, K):\n",
    "    k_plus_plus = 1\n",
    "    mC = InitKMeans(data, K, k_plus_plus)\n",
    "    mC, vL, lO = KMeans(data, mC, 1000, 1e-5)\n",
    "    return vL\n",
    "\n",
    "def SoftGMM_lambda(data, K):\n",
    "    mμ, tΣ, vW = InitGmm(data, K)\n",
    "    initialize = mμ.copy()\n",
    "    mμ, tΣ, vW, vL, lO = GMM(data, initialize, tΣ, vW, 1000, 1e-5)\n",
    "    return vL\n",
    "\n",
    "methods = [{\n",
    "                'method_name': 'K-means',\n",
    "                'has_noise_points': False,\n",
    "                'function': lambda dataset, n_clusters, _, __: KMeans_lambda(dataset, n_clusters),\n",
    "            },\n",
    "            {\n",
    "                'method_name': 'Soft GMM',\n",
    "                'has_noise_points': False,\n",
    "                'function': lambda dataset, n_clusters, _, __: SoftGMM_lambda(dataset, n_clusters),\n",
    "            },\n",
    "            {\n",
    "                'method_name': 'DBScan',\n",
    "                'has_noise_points': True,\n",
    "                'function': lambda dataset, n_clusters, Z, r: DBSCAN(dataset, Z, r),\n",
    "            },\n",
    "            {\n",
    "                'method_name': 'Agglomerative',\n",
    "                'has_noise_points': False,\n",
    "                'function': lambda dataset, n_clusters, _, __: AgglomerativeClustering(n_clusters).fit(dataset).labels_,\n",
    "            }]\n",
    "\n",
    "datasets = [{\n",
    "                'dataset_name': 'mX1',\n",
    "                'dataset': mX1,\n",
    "                'optimal_cluster_number': 2,\n",
    "                'optimal_Z': 4,\n",
    "                'optimal_r': 0.06,\n",
    "            },\n",
    "            {\n",
    "                'dataset_name': 'mX2',\n",
    "                'dataset': mX2,\n",
    "                'optimal_cluster_number': 2,\n",
    "                'optimal_Z': 4,\n",
    "                'optimal_r': 0.09,\n",
    "            },\n",
    "            {\n",
    "                'dataset_name': 'mX3',\n",
    "                'dataset': mX3,\n",
    "                'optimal_cluster_number': 3,\n",
    "                'optimal_Z': 5,\n",
    "                'optimal_r': 0.35,\n",
    "            },\n",
    "            {\n",
    "                'dataset_name': 'mX4',\n",
    "                'dataset': mX4,\n",
    "                'optimal_cluster_number': 3,\n",
    "                'optimal_Z': 5,\n",
    "                'optimal_r': 0.688,\n",
    "            },\n",
    "            {\n",
    "                'dataset_name': 'mX5',\n",
    "                'dataset': mX5,\n",
    "                'optimal_cluster_number': 2,\n",
    "                'optimal_Z': 8,\n",
    "                'optimal_r': 0.038,\n",
    "            }]\n",
    "\n",
    "results = np.random.rand(len(methods), len(datasets))  # Replace with your actual results\n",
    "\n",
    "# Step 2: Plot a grid of scatter plots\n",
    "fig, axes = plt.subplots(nrows=len(methods), ncols=len(datasets), figsize=(12, 10))\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        ax = axes[i][j]\n",
    "        mX = dataset['dataset']\n",
    "\n",
    "        labels = method['function'](dataset['dataset'], dataset['optimal_cluster_number'], dataset['optimal_Z'], dataset['optimal_r'])\n",
    "        unique_labels = set(labels) - {-1}\n",
    "\n",
    "        colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "        for label, color in zip(unique_labels, colors):\n",
    "            if method['has_noise_points'] and label == 0:\n",
    "                noise_samples = mX[labels == 0]\n",
    "                ax.scatter(noise_samples[:, 0], noise_samples[:, 1], c='black', label='Noise', marker='x')\n",
    "            else:\n",
    "                cluster_samples = mX[labels == label]\n",
    "                ax.scatter(cluster_samples[:, 0], cluster_samples[:, 1], c=color, label=f'Cluster {label}')\n",
    "\n",
    "        ax.set_title(f'{method[\"method_name\"]} on {dataset[\"dataset_name\"]}')\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "\n",
    "fig.suptitle('Clustering Results', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#===============================================================#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Royi: ❌, Exaggerated run time.  \n",
    "> Royi: <font color='red'>-4</font>.\n",
    "\n",
    "![](https://i.imgur.com/Y8JeBhi.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "39577bab1f263e62e0b74f5b8086bd735049bf4751f6562b2d4b2969dc308293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
